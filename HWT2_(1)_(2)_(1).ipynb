{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Cehb_Ovkzr",
        "outputId": "dc3a6bde-e4a9-42a9-e540-fd1894d924a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HiGAN training/generation"
      ],
      "metadata": {
        "id": "ScRryt-ruC6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "technical stuff"
      ],
      "metadata": {
        "id": "3T2xtm6HwrSV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RmiEuTrjSLE"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/HWT/HiGAN /content/HiGAN #if HiGAN\n",
        "%cd /content/HiGAN/HiGAN-main\n",
        "!pip install -r requirements.txt\n",
        "!pip install --force-reinstall torch==1.11.0\n",
        "!pip install --force-reinstall protobuf==3.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7PySFwkXfmU"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/HWT/HiGAN+ /content/HiGAN+ #if HiGAN+\n",
        "%cd /content/HiGAN+\n",
        "!pip install munch distance\n",
        "!pip install --force-reinstall torch==1.11.0\n",
        "!pip install --force-reinstall protobuf==3.9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training"
      ],
      "metadata": {
        "id": "oIXQ8d8rwxs_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8l82QHlXiAQ"
      },
      "outputs": [],
      "source": [
        "!python train.py --config ./configs/gan_iam.yml"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generating dataset reproducing words from cyrillic or notebooks dataset - which one is specified in configuraton file"
      ],
      "metadata": {
        "id": "AONKmLx3wzRn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV2cxgUlfS1F"
      },
      "outputs": [],
      "source": [
        "!python eval_demo.py --config ./configs/gan_iam.yml --ckpt ./ckpt/last1.pth --mode repro #if HiGAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_demo.py --config ./configs/gan_iam.yml --mode repro #if HiGAN+"
      ],
      "metadata": {
        "id": "U2sN8AcyCMgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing cyrillic handwriting dataset"
      ],
      "metadata": {
        "id": "3XHAW-DVuTkY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2h0tYaam5s-"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/HWT/archive.zip archive.zip\n",
        "!unzip archive.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking which symbols are present"
      ],
      "metadata": {
        "id": "_wYcKWkSxF0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkx6EzNO-sXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fc57a6-cfbf-4223-a680-8f483fc34875"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' !\"%\\'()+,-./0123456789:;=?R[]abcehinoprstuxy«»АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяё№',\n",
              " 109)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import pandas as pd\n",
        "test=pd.read_table('test.tsv', header=None)\n",
        "train=pd.read_table('train.tsv', header=None)\n",
        "chars=set()\n",
        "for i in train[1]:\n",
        "  for j in str(i):\n",
        "      chars.add(j)\n",
        "for i in test[1]:\n",
        "  for j in str(i):\n",
        "      chars.add(j)\n",
        "''.join(sorted(list(chars))), len(chars)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "processing cyrillic handwriting dataset to fit the input format for model training"
      ],
      "metadata": {
        "id": "smllaAtqxMy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVZI1Wuq4RsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14950adf-ca2c-4ca7-f04b-560f87085a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 test0.png\n",
            "200 test1190.png\n",
            "400 test1390.png\n",
            "{'test': 0, 'testt': 1}\n",
            "600 test168.png\n",
            "800 test349.png\n",
            "1000 test537.png\n",
            "1200 test722.png\n",
            "1400 test921.png\n",
            "{'test': 0, 'testt': 1, 'testtt': 2}\n",
            "end_of_dataset\n"
          ]
        }
      ],
      "source": [
        "# stuff in this cell is taken from github.com/MuellerDominik/HiGANplus and slightly modified to fit the format of cyrillic dataset\n",
        "import re\n",
        "import itertools\n",
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from os import path\n",
        "from PIL import Image\n",
        "\n",
        "def gen_h5file(all_imgs, #saving in hdf format\n",
        "               all_texts,\n",
        "               all_wids,\n",
        "               save_name):\n",
        "\n",
        "    img_seek_idxs, img_lens = [], []\n",
        "    cur_seek_idx = 0\n",
        "    for img in all_imgs:\n",
        "        img_seek_idxs.append(cur_seek_idx)\n",
        "        img_lens.append(img.shape[-1])\n",
        "        cur_seek_idx += img.shape[-1]\n",
        "\n",
        "    lb_seek_idxs, lb_lens = [], []\n",
        "    cur_seek_idx = 0\n",
        "    for lb in all_texts:\n",
        "        lb_seek_idxs.append(cur_seek_idx)\n",
        "        lb_lens.append(len(lb))\n",
        "        cur_seek_idx += len(lb)\n",
        "\n",
        "    save_imgs = np.concatenate(all_imgs, axis=-1)\n",
        "    save_texts = list(itertools.chain(*all_texts))\n",
        "    save_lbs = [ord(ch) for ch in save_texts]\n",
        "    save_path = os.path.join(save_name + '.hdf5')\n",
        "    h5f = h5py.File(save_path, 'w')\n",
        "    h5f.create_dataset('imgs',\n",
        "                       data=save_imgs,\n",
        "                       compression='gzip',\n",
        "                       compression_opts=4,\n",
        "                       dtype=np.uint8)\n",
        "    h5f.create_dataset('lbs',\n",
        "                       data=save_lbs,\n",
        "                       dtype=np.int32)\n",
        "    h5f.create_dataset('img_seek_idxs',\n",
        "                       data=img_seek_idxs,\n",
        "                       dtype=np.int64)\n",
        "    h5f.create_dataset('img_lens',\n",
        "                       data=img_lens,\n",
        "                       dtype=np.int16)\n",
        "    h5f.create_dataset('lb_seek_idxs',\n",
        "                       data=lb_seek_idxs,\n",
        "                       dtype=np.int64)\n",
        "    h5f.create_dataset('lb_lens',\n",
        "                       data=lb_lens,\n",
        "                       dtype=np.int16)\n",
        "    h5f.create_dataset('wids',\n",
        "                       data=all_wids,\n",
        "                       dtype=np.int16)\n",
        "    h5f.close()\n",
        "    print('save->', save_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Choose whether the train or test set should be generated (uncomment needed)\n",
        "is_test = True\n",
        "# is_test = False\n",
        "# data=train\n",
        "data=test\n",
        "\n",
        "# Choosing Input Directory\n",
        "if is_test == True:\n",
        "    input_dir = './test/'\n",
        "else:\n",
        "    input_dir = './train/'\n",
        "\n",
        "all_wids = np.empty((0,))\n",
        "all_texts = []\n",
        "all_imgs = []\n",
        "words_list = []\n",
        "\n",
        "writers_dict={}\n",
        "imsize=32 #set 32 for higan and 64 for higan+\n",
        "save=True #if we want to replace original data in directory too, not only save in hdf5\n",
        "for idx, line in data.iterrows():\n",
        "        file_name=line[0]\n",
        "        text=line[1]\n",
        "        if not idx%200:\n",
        "          print(idx, file_name)\n",
        "        image = cv2.imread(os.path.join(input_dir, file_name))\n",
        "\n",
        "        # Image Information:\n",
        "        string_parts = str(text)\n",
        "        word_length = len(string_parts)\n",
        "        # Saving the words to generate a txt file\n",
        "        word = string_parts\n",
        "        words_list.append(word)\n",
        "\n",
        "        # Numpy array with the writer ID's:\n",
        "        author=re.sub(r'[^a-zA-Z]', '', file_name[:-4]) #author identifier is in file name, e.g. aa or yob\n",
        "        if author in writers_dict:\n",
        "          writer_ID=writers_dict[author]\n",
        "        elif not writers_dict:\n",
        "          writer_ID=0\n",
        "          writers_dict[author]=0\n",
        "        else:\n",
        "          writer_ID=max(list(writers_dict.values()))+1\n",
        "          writers_dict[author]=writer_ID\n",
        "          print(writers_dict)\n",
        "        writer_ID = int(writer_ID)\n",
        "        all_wids = np.append(all_wids, writer_ID)\n",
        "\n",
        "        # Numpy array with label text:\n",
        "        all_texts.append(string_parts)\n",
        "\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        # Denoiseing Image\n",
        "        #  Apply erosion to the binary image\n",
        "        denoised = cv2.erode(gray, (5, 5), iterations=1)\n",
        "        # Threshold the image to binary\n",
        "        _, binary = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "        # Find the contours of the handwriting\n",
        "        x, y, w, h = cv2.boundingRect(binary)\n",
        "        cv2.rectangle(binary, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        # Crop the image to the bounding box\n",
        "        handwriting = gray[y:y + h, x:x + w]\n",
        "        # Resize the images while keeping the aspect ratio the same\n",
        "        original_aspect_ratio = handwriting.shape[1] / handwriting.shape[0]\n",
        "        resized_image = cv2.resize(handwriting, (int(imsize * original_aspect_ratio), imsize))\n",
        "        # Inverting the image:\n",
        "        _, resized_binary = cv2.threshold(resized_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "        # Numpy matrix with all the pre-processed images:\n",
        "        all_imgs.append(resized_binary)\n",
        "\n",
        "        if save:\n",
        "          _, resized_binary = cv2.threshold(resized_image, 0, 255, cv2.THRESH_OTSU)\n",
        "          cv2.imwrite(os.path.join(input_dir, file_name), resized_binary)\n",
        "print(\"end_of_dataset\")\n",
        "\n",
        "# Hdf5 File Generation:\n",
        "if is_test == True:\n",
        "    gen_h5file(all_imgs, all_texts, all_wids, '/content/drive/MyDrive/HWT/cyrillic/ru_hdf5_file_test')\n",
        "else:\n",
        "    gen_h5file(all_imgs, all_texts, all_wids, '/content/drive/MyDrive/HWT/cyrillic/ru_hdf5_file_train')\n",
        "\n",
        "\n",
        "# Generating a txt file to test the model: c\n",
        "if is_test == True:\n",
        "    with open('/content/drive/MyDrive/HWT/cyrillic/ru_test_words.txt', 'w') as f:\n",
        "        # Write each item in the list to the file on a new line\n",
        "        for item in words_list:\n",
        "            f.write(str(item) + '\\n')\n",
        "else:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebooks"
      ],
      "metadata": {
        "id": "1WrcXbxivWHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting words from notebooks dataset - if pictures are also needed, uncomment commented parts"
      ],
      "metadata": {
        "id": "XL7KRHZny8pp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U67v8uXutRUu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "%cd ./notebooks/\n",
        "for group in ['train', 'test', 'val']:\n",
        "  k=0\n",
        "  with open('annotations_'+group+'.json') as f:\n",
        "    dat=json.load(f)\n",
        "  print(group, len(dat['annotations']))\n",
        "  imgs={img['id']:img['file_name'] for img in dat['images']}\n",
        "  crops={}\n",
        "  prev=''\n",
        "  for word in dat['annotations']:\n",
        "    k+=1\n",
        "    if not k%1000:\n",
        "      print(k)\n",
        "    if not 'attributes' in word: #if some polygon doesn't describe any word/symbolic sequence\n",
        "      continue\n",
        "    #forming new filename (old+number of word derived)\n",
        "    filename=imgs[word['image_id']]\n",
        "    if not filename in crops:\n",
        "      crops[filename]=0\n",
        "    else:\n",
        "      crops[filename]=crops[filename]+1\n",
        "    name=filename+'_'+str(crops[filename]) #+'.jpg'\n",
        "    # if os.path.exists(group+'/'+name):\n",
        "    #   continue\n",
        "    # if not filename==prev: #to read img only once\n",
        "    #   img = cv2.imread('./images/images/'+filename)\n",
        "    # prev=filename\n",
        "    #getting text\n",
        "    text=word['attributes']['translation']\n",
        "    # #cutting polygon with word from notebook page and saving in distinct file\n",
        "    # mask = np.zeros(img.shape[0:2], dtype=np.uint8)\n",
        "    # xs=word['segmentation'][0][::2]\n",
        "    # ys=word['segmentation'][0][1::2]\n",
        "    # points = np.array([[[int(xs[i]), int(ys[i])] for i in range(len(xs))]])\n",
        "    # cv2.drawContours(mask, [points], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
        "    # res = cv2.bitwise_and(img,img,mask = mask)\n",
        "    # rect = cv2.boundingRect(points) # returns (x,y,w,h) of the rect\n",
        "    # cropped = res[rect[1]: rect[1] + rect[3], rect[0]: rect[0] + rect[2]]\n",
        "    # wbg = np.ones_like(img, np.uint8)*255\n",
        "    # cv2.bitwise_not(wbg,wbg, mask=mask)\n",
        "    # dst = wbg+res\n",
        "    # dst=dst[rect[1]: rect[1] + rect[3], rect[0]: rect[0] + rect[2]]\n",
        "    # cv2.imwrite(group+'/'+name, dst)\n",
        "\n",
        "    #making index\n",
        "    w=pd.DataFrame([[name, text]], columns=['file', 'text'])\n",
        "    w.to_csv('/content/'+group+'v2'+'.csv', mode='a', header=not os.path.exists('/content/'+group+'v2'+'.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "c924woMtvZVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "installations and imports"
      ],
      "metadata": {
        "id": "LOG3tjH20c4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install torchmetrics[image]\n",
        "!conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.8\n",
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git\n"
      ],
      "metadata": {
        "id": "igwVQzOHvEH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import clip\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "RF_QExUXuvVd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting data"
      ],
      "metadata": {
        "id": "Fa2YGzox0goW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/HWT/archive.zip archive.zip\n",
        "!unzip archive.zip\n",
        "!cp /content/drive/MyDrive/HWT/cyrillic_repro.zip repro.zip\n",
        "!unzip repro.zip"
      ],
      "metadata": {
        "id": "6ihOFtaST3e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/HWT/cyrillic_repro+.zip repro.zip\n",
        "!unzip repro.zip"
      ],
      "metadata": {
        "id": "w0atiPaCESe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading index"
      ],
      "metadata": {
        "id": "6Uq_BRPE0i6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_train=pd.read_table('train.tsv', header=None)\n",
        "real_test=pd.read_table('test.tsv', header=None)\n",
        "fake_test=pd.read_csv('test.csv')\n",
        "fake_test=fake_test[fake_test['file'].str.endswith('0.png')][['file', 'text']]\n",
        "fake_train=pd.read_csv('train.csv')\n",
        "fake_train=fake_train[fake_train['file'].str.endswith('0.png')]"
      ],
      "metadata": {
        "id": "pLTfg3Q_219L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "counting letters"
      ],
      "metadata": {
        "id": "jpVGvfqu0l8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letters=[j for i in real_train[1].values for j in str(i)]\n",
        "cnt=dict(Counter(letters))\n",
        "for i in sorted(cnt, key=cnt.get):\n",
        "  print(i, cnt[i], round(cnt[i]/len(letters)*100, 2))"
      ],
      "metadata": {
        "id": "jlmkgBN-SxSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DS(Dataset):\n",
        "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.labels.iloc[idx, 0]\n",
        "        fullname = os.path.join(self.root_dir, img_name)\n",
        "        image = Image.open(fullname).convert('RGB')\n",
        "        labels = self.labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return [image, labels]"
      ],
      "metadata": {
        "id": "1aaJRWyGW_Lp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FID"
      ],
      "metadata": {
        "id": "veypRn3CvuVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "conventional FID calculation"
      ],
      "metadata": {
        "id": "kT5l4WZL00tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(299),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "]) #how to preprocess data to fit inception input\n",
        "real = DS(real_train, 'train', transform=preprocess)\n",
        "fake= DS(fake_train, 'train', transform=preprocess)\n",
        "bs=128\n",
        "nw=2\n",
        "real_dl = DataLoader(real, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "fake_dl = DataLoader(fake, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "fid = FrechetInceptionDistance(normalize=True).to(device)\n",
        "k=0\n",
        "#going through real and fake data to update means and covariance online\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute() #finally, calculating FID"
      ],
      "metadata": {
        "id": "G1EAb4GHX4MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding test data up to train"
      ],
      "metadata": {
        "id": "o-UweZ9q1M0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real = DS(real_test, 'test', transform=preprocess)\n",
        "fake= DS(fake_test, 'test', transform=preprocess)\n",
        "real_dl = DataLoader(real, batch_size=bs, num_workers=nw)\n",
        "fake_dl = DataLoader(fake, batch_size=bs, num_workers=nw)\n",
        "k=0\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute()"
      ],
      "metadata": {
        "id": "8Ar8dV-G4Rr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test without train"
      ],
      "metadata": {
        "id": "M-5koBpY1QrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fid = FrechetInceptionDistance(normalize=True).to(device)\n",
        "k=0\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute()"
      ],
      "metadata": {
        "id": "Blo6F6mujwGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clip"
      ],
      "metadata": {
        "id": "8d-X5WZXvrKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "same things as for conventional FID but CLIP in wrapper instead of inception"
      ],
      "metadata": {
        "id": "E3ArpFkQ1S1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "class ClipWrapper(nn.Module):\n",
        "  def __init__(self, clip, preprocess):\n",
        "    super().__init__()\n",
        "    self.clip=clip\n",
        "    self.prefix=prefix\n",
        "    self.preprocess=preprocess\n",
        "    self.transform = T.ToPILImage()\n",
        "  def forward(self, x):\n",
        "    batch_features=[]\n",
        "    with torch.no_grad():\n",
        "      if x.shape[0]==1: #when initialising FID, it passes dummy input through model, this is for this dummy input to fit CLIP\n",
        "        x=self.transform(x[0])\n",
        "        image = self.preprocess(x).unsqueeze(0).to(device)\n",
        "        image_features = model.encode_image(image)\n",
        "        batch_features.append(image_features)\n",
        "        return torch.cat(batch_features)\n",
        "      else:\n",
        "        return model.encode_image(x)\n",
        "    \n",
        "clip_w=ClipWrapper(model, preprocess)\n",
        "\n",
        "fid = FrechetInceptionDistance(feature=clip_w, reset_real_features=True).to(device)"
      ],
      "metadata": {
        "id": "ouTfFZ1f9oon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = DS(real_train, 'train', transform=preprocess)\n",
        "fake= DS(fake_train, 'train', transform=preprocess)\n",
        "bs=128\n",
        "nw=2\n",
        "real_dl = DataLoader(real, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "fake_dl = DataLoader(fake, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "k=0\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute()"
      ],
      "metadata": {
        "id": "x7LFH01b-Dhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = DS(real_test, 'test', transform=preprocess)\n",
        "fake= DS(fake_test, 'test', transform=preprocess)\n",
        "real_dl = DataLoader(real, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "fake_dl = DataLoader(fake, batch_size=bs, shuffle=True, num_workers=nw)\n",
        "k=0\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute()"
      ],
      "metadata": {
        "id": "X1G15Dr5AH0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fid = FrechetInceptionDistance(feature=clip_w, reset_real_features=True).to(device)\n",
        "k=0\n",
        "for x, y in real_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=True)\n",
        "k=0\n",
        "for x, y in fake_dl:\n",
        "  k+=1\n",
        "  print(k)\n",
        "  fid.update(x.to(device), real=False)\n",
        "fid.compute()"
      ],
      "metadata": {
        "id": "NGnBucIz-WN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ScRryt-ruC6z"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}